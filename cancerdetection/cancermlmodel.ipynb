{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"brca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x.radius_mean</th>\n",
       "      <th>x.texture_mean</th>\n",
       "      <th>x.perimeter_mean</th>\n",
       "      <th>x.area_mean</th>\n",
       "      <th>x.smoothness_mean</th>\n",
       "      <th>x.compactness_mean</th>\n",
       "      <th>x.concavity_mean</th>\n",
       "      <th>x.concave_pts_mean</th>\n",
       "      <th>x.symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>x.texture_worst</th>\n",
       "      <th>x.perimeter_worst</th>\n",
       "      <th>x.area_worst</th>\n",
       "      <th>x.smoothness_worst</th>\n",
       "      <th>x.compactness_worst</th>\n",
       "      <th>x.concavity_worst</th>\n",
       "      <th>x.concave_pts_worst</th>\n",
       "      <th>x.symmetry_worst</th>\n",
       "      <th>x.fractal_dim_worst</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>...</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>...</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.030</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.02562</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>...</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.06169</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "      <td>201.9</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.01588</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>...</td>\n",
       "      <td>21.96</td>\n",
       "      <td>57.26</td>\n",
       "      <td>242.2</td>\n",
       "      <td>0.12970</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.06880</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.07409</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>565</td>\n",
       "      <td>20.920</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.31740</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>...</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.65990</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>566</td>\n",
       "      <td>21.560</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>567</td>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>568</td>\n",
       "      <td>16.600</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>569</td>\n",
       "      <td>20.600</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  x.radius_mean  x.texture_mean  x.perimeter_mean  x.area_mean   \n",
       "0             1         13.540           14.36             87.46        566.3  \\\n",
       "1             2         13.080           15.71             85.63        520.0   \n",
       "2             3          9.504           12.44             60.34        273.9   \n",
       "3             4         13.030           18.42             82.61        523.8   \n",
       "4             5          8.196           16.84             51.71        201.9   \n",
       "..          ...            ...             ...               ...          ...   \n",
       "564         565         20.920           25.09            143.00       1347.0   \n",
       "565         566         21.560           22.39            142.00       1479.0   \n",
       "566         567         20.130           28.25            131.20       1261.0   \n",
       "567         568         16.600           28.08            108.30        858.1   \n",
       "568         569         20.600           29.33            140.10       1265.0   \n",
       "\n",
       "     x.smoothness_mean  x.compactness_mean  x.concavity_mean   \n",
       "0              0.09779             0.08129           0.06664  \\\n",
       "1              0.10750             0.12700           0.04568   \n",
       "2              0.10240             0.06492           0.02956   \n",
       "3              0.08983             0.03766           0.02562   \n",
       "4              0.08600             0.05943           0.01588   \n",
       "..                 ...                 ...               ...   \n",
       "564            0.10990             0.22360           0.31740   \n",
       "565            0.11100             0.11590           0.24390   \n",
       "566            0.09780             0.10340           0.14400   \n",
       "567            0.08455             0.10230           0.09251   \n",
       "568            0.11780             0.27700           0.35140   \n",
       "\n",
       "     x.concave_pts_mean  x.symmetry_mean  ...  x.texture_worst   \n",
       "0              0.047810           0.1885  ...            19.26  \\\n",
       "1              0.031100           0.1967  ...            20.49   \n",
       "2              0.020760           0.1815  ...            15.66   \n",
       "3              0.029230           0.1467  ...            22.81   \n",
       "4              0.005917           0.1769  ...            21.96   \n",
       "..                  ...              ...  ...              ...   \n",
       "564            0.147400           0.2149  ...            29.41   \n",
       "565            0.138900           0.1726  ...            26.40   \n",
       "566            0.097910           0.1752  ...            38.25   \n",
       "567            0.053020           0.1590  ...            34.12   \n",
       "568            0.152000           0.2397  ...            39.42   \n",
       "\n",
       "     x.perimeter_worst  x.area_worst  x.smoothness_worst  x.compactness_worst   \n",
       "0                99.70         711.2             0.14400              0.17730  \\\n",
       "1                96.09         630.5             0.13120              0.27760   \n",
       "2                65.13         314.9             0.13240              0.11480   \n",
       "3                84.46         545.9             0.09701              0.04619   \n",
       "4                57.26         242.2             0.12970              0.13570   \n",
       "..                 ...           ...                 ...                  ...   \n",
       "564             179.10        1819.0             0.14070              0.41860   \n",
       "565             166.10        2027.0             0.14100              0.21130   \n",
       "566             155.00        1731.0             0.11660              0.19220   \n",
       "567             126.70        1124.0             0.11390              0.30940   \n",
       "568             184.60        1821.0             0.16500              0.86810   \n",
       "\n",
       "     x.concavity_worst  x.concave_pts_worst  x.symmetry_worst   \n",
       "0              0.23900              0.12880            0.2977  \\\n",
       "1              0.18900              0.07283            0.3184   \n",
       "2              0.08867              0.06227            0.2450   \n",
       "3              0.04833              0.05013            0.1987   \n",
       "4              0.06880              0.02564            0.3105   \n",
       "..                 ...                  ...               ...   \n",
       "564            0.65990              0.25420            0.2929   \n",
       "565            0.41070              0.22160            0.2060   \n",
       "566            0.32150              0.16280            0.2572   \n",
       "567            0.34030              0.14180            0.2218   \n",
       "568            0.93870              0.26500            0.4087   \n",
       "\n",
       "     x.fractal_dim_worst  y  \n",
       "0                0.07259  B  \n",
       "1                0.08183  B  \n",
       "2                0.07773  B  \n",
       "3                0.06169  B  \n",
       "4                0.07409  B  \n",
       "..                   ... ..  \n",
       "564              0.09873  M  \n",
       "565              0.07115  M  \n",
       "566              0.06637  M  \n",
       "567              0.07820  M  \n",
       "568              0.12400  M  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data = data.drop_duplicates()\n",
    "X = data.drop('y', axis=1)\n",
    "y = data['y']\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0               int64\n",
       "x.radius_mean          float64\n",
       "x.texture_mean         float64\n",
       "x.perimeter_mean       float64\n",
       "x.area_mean            float64\n",
       "x.smoothness_mean      float64\n",
       "x.compactness_mean     float64\n",
       "x.concavity_mean       float64\n",
       "x.concave_pts_mean     float64\n",
       "x.symmetry_mean        float64\n",
       "x.fractal_dim_mean     float64\n",
       "x.radius_se            float64\n",
       "x.texture_se           float64\n",
       "x.perimeter_se         float64\n",
       "x.area_se              float64\n",
       "x.smoothness_se        float64\n",
       "x.compactness_se       float64\n",
       "x.concavity_se         float64\n",
       "x.concave_pts_se       float64\n",
       "x.symmetry_se          float64\n",
       "x.fractal_dim_se       float64\n",
       "x.radius_worst         float64\n",
       "x.texture_worst        float64\n",
       "x.perimeter_worst      float64\n",
       "x.area_worst           float64\n",
       "x.smoothness_worst     float64\n",
       "x.compactness_worst    float64\n",
       "x.concavity_worst      float64\n",
       "x.concave_pts_worst    float64\n",
       "x.symmetry_worst       float64\n",
       "x.fractal_dim_worst    float64\n",
       "y                       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    ExtraTreesClassifier()\n",
    "]\n",
    "\n",
    "# List to store model performance\n",
    "model_names = []\n",
    "performance = []\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # Train the model\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "    # Make predictions on the testing set\n",
    "    predictions = classifier.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    roc_auc = roc_auc_score(y_test, predictions)\n",
    "    # Store model performance\n",
    "    model_names.append(classifier.__class__.__name__)\n",
    "    performance.append([accuracy, precision, recall, f1, roc_auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result\n",
      "\n",
      "+----------------------------+------------+-------------+----------+------------+-----------+\n",
      "|                            |   Accuracy |   Precision |   Recall |   F1-Score |   ROC AUC |\n",
      "|----------------------------+------------+-------------+----------+------------+-----------|\n",
      "| LogisticRegression         |   0.991228 |       1     | 0.976744 |   0.988235 |  0.988372 |\n",
      "| RandomForestClassifier     |   1        |       1     | 1        |   1        |  1        |\n",
      "| GradientBoostingClassifier |   1        |       1     | 1        |   1        |  1        |\n",
      "| SVC                        |   0.991228 |       1     | 0.976744 |   0.988235 |  0.988372 |\n",
      "| KNeighborsClassifier       |   0.95614  |       0.975 | 0.906977 |   0.939759 |  0.946446 |\n",
      "| AdaBoostClassifier         |   1        |       1     | 1        |   1        |  1        |\n",
      "| ExtraTreesClassifier       |   0.982456 |       1     | 0.953488 |   0.97619  |  0.976744 |\n",
      "+----------------------------+------------+-------------+----------+------------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "performance_df = pd.DataFrame(performance, columns=['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC'], index=model_names)\n",
    "\n",
    "# Print model performance table\n",
    "print(f'\\nResult\\n')\n",
    "print(tabulate(performance_df, headers='keys', tablefmt='psql'))\n",
    "print()\n",
    "\n",
    "# Create a bar plot to compare model accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=performance_df['Accuracy'], y=performance_df.index, color='steelblue')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Model')\n",
    "plt.title('Comparison of Model Accuracies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logisticmodel.joblib']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import load, dump\n",
    "dump(model, 'logisticmodel.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\2591712217.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\2591712217.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x.radius_se  x.radius_worst\n",
      "0       0.2976            12.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "X = data[['x.radius_mean']] \n",
    "y = data[['x.radius_se', 'x.radius_worst']] \n",
    "\n",
    "label_encoders = {}\n",
    "for column in y.columns:\n",
    "    le = LabelEncoder()\n",
    "    y[column] = le.fit_transform(y[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "multi_output_model1 = MultiOutputClassifier(model)\n",
    "\n",
    "multi_output_model1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predictions = multi_output_model1.predict([[12.05]])\n",
    "\n",
    "decoded_predictions = pd.DataFrame(columns=y.columns)\n",
    "for column in y.columns:\n",
    "    le = label_encoders[column]\n",
    "    decoded_predictions[column] = le.inverse_transform(predictions[:, list(y.columns).index(column)])\n",
    "\n",
    "print(decoded_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\2759508843.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\2759508843.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x.texture_se  x.texture_worst\n",
      "0        0.9053            15.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "X = data[['x.texture_mean']] \n",
    "y = data[['x.texture_se', 'x.texture_worst']] \n",
    "\n",
    "label_encoders = {}\n",
    "for column in y.columns:\n",
    "    le = LabelEncoder()\n",
    "    y[column] = le.fit_transform(y[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "multi_output_model2 = MultiOutputClassifier(model)\n",
    "\n",
    "multi_output_model2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predictions = multi_output_model2.predict([[12.05]])\n",
    "\n",
    "decoded_predictions = pd.DataFrame(columns=y.columns)\n",
    "for column in y.columns:\n",
    "    le = label_encoders[column]\n",
    "    decoded_predictions[column] = le.inverse_transform(predictions[:, list(y.columns).index(column)])\n",
    "\n",
    "print(decoded_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\79919228.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\79919228.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x.perimeter_se  x.perimeter_worst\n",
      "0           1.243              50.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "X = data[['x.perimeter_mean']] \n",
    "y = data[['x.perimeter_se', 'x.perimeter_worst']] \n",
    "\n",
    "label_encoders = {}\n",
    "for column in y.columns:\n",
    "    le = LabelEncoder()\n",
    "    y[column] = le.fit_transform(y[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "multi_output_model3 = MultiOutputClassifier(model)\n",
    "\n",
    "multi_output_model3.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predictions = multi_output_model3.predict([[12.05]])\n",
    "\n",
    "decoded_predictions = pd.DataFrame(columns=y.columns)\n",
    "for column in y.columns:\n",
    "    le = label_encoders[column]\n",
    "    decoded_predictions[column] = le.inverse_transform(predictions[:, list(y.columns).index(column)])\n",
    "\n",
    "print(decoded_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\818591601.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\818591601.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x.area_se  x.area_worst\n",
      "0      17.67         284.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "X = data[['x.area_mean']] \n",
    "y = data[['x.area_se', 'x.area_worst']] \n",
    "\n",
    "label_encoders = {}\n",
    "for column in y.columns:\n",
    "    le = LabelEncoder()\n",
    "    y[column] = le.fit_transform(y[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "multi_output_model4 = MultiOutputClassifier(model)\n",
    "\n",
    "multi_output_model4.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predictions = multi_output_model4.predict([[12.05]])\n",
    "\n",
    "decoded_predictions = pd.DataFrame(columns=y.columns)\n",
    "for column in y.columns:\n",
    "    le = label_encoders[column]\n",
    "    decoded_predictions[column] = le.inverse_transform(predictions[:, list(y.columns).index(column)])\n",
    "\n",
    "print(decoded_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x.smoothness_se  x.smoothness_worst\n",
      "0             0.01              0.1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\3417423962.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\3417423962.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "X = data[['x.smoothness_mean']] \n",
    "y = data[['x.smoothness_se', 'x.smoothness_worst']] \n",
    "\n",
    "label_encoders = {}\n",
    "for column in y.columns:\n",
    "    le = LabelEncoder()\n",
    "    y[column] = le.fit_transform(y[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "multi_output_model5 = MultiOutputClassifier(model)\n",
    "\n",
    "multi_output_model5.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predictions = multi_output_model5.predict([[12.05]])\n",
    "\n",
    "decoded_predictions = pd.DataFrame(columns=y.columns)\n",
    "for column in y.columns:\n",
    "    le = label_encoders[column]\n",
    "    decoded_predictions[column] = le.inverse_transform(predictions[:, list(y.columns).index(column)])\n",
    "\n",
    "print(decoded_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x.compactness_se  x.compactness_worst\n",
      "0           0.06835               0.6164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\2531222561.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\2531222561.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "X = data[['x.compactness_mean']] \n",
    "y = data[['x.compactness_se', 'x.compactness_worst']] \n",
    "\n",
    "label_encoders = {}\n",
    "for column in y.columns:\n",
    "    le = LabelEncoder()\n",
    "    y[column] = le.fit_transform(y[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "multi_output_model6 = MultiOutputClassifier(model)\n",
    "\n",
    "multi_output_model6.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predictions = multi_output_model6.predict([[12.05]])\n",
    "\n",
    "decoded_predictions = pd.DataFrame(columns=y.columns)\n",
    "for column in y.columns:\n",
    "    le = label_encoders[column]\n",
    "    decoded_predictions[column] = le.inverse_transform(predictions[:, list(y.columns).index(column)])\n",
    "\n",
    "print(decoded_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x.concavity_se  x.concavity_worst\n",
      "0          0.1278             0.5803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\498856891.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\498856891.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "X = data[['x.concavity_mean']] \n",
    "y = data[['x.concavity_se', 'x.concavity_worst']] \n",
    "\n",
    "label_encoders = {}\n",
    "for column in y.columns:\n",
    "    le = LabelEncoder()\n",
    "    y[column] = le.fit_transform(y[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "multi_output_model7 = MultiOutputClassifier(model)\n",
    "\n",
    "multi_output_model7.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predictions = multi_output_model7.predict([[12.05]])\n",
    "\n",
    "decoded_predictions = pd.DataFrame(columns=y.columns)\n",
    "for column in y.columns:\n",
    "    le = label_encoders[column]\n",
    "    decoded_predictions[column] = le.inverse_transform(predictions[:, list(y.columns).index(column)])\n",
    "\n",
    "print(decoded_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x.concave_pts_se  x.concave_pts_worst\n",
      "0           0.01843               0.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\2325806789.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\2325806789.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "X = data[['x.concave_pts_mean']] \n",
    "y = data[['x.concave_pts_se', 'x.concave_pts_worst']] \n",
    "\n",
    "label_encoders = {}\n",
    "for column in y.columns:\n",
    "    le = LabelEncoder()\n",
    "    y[column] = le.fit_transform(y[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "multi_output_model8 = MultiOutputClassifier(model)\n",
    "\n",
    "multi_output_model8.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predictions = multi_output_model8.predict([[12.05]])\n",
    "\n",
    "decoded_predictions = pd.DataFrame(columns=y.columns)\n",
    "for column in y.columns:\n",
    "    le = label_encoders[column]\n",
    "    decoded_predictions[column] = le.inverse_transform(predictions[:, list(y.columns).index(column)])\n",
    "\n",
    "print(decoded_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x.symmetry_se  x.symmetry_worst\n",
      "0        0.01798            0.3196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\1392979072.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\1392979072.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "X = data[['x.symmetry_mean']] \n",
    "y = data[['x.symmetry_se', 'x.symmetry_worst']] \n",
    "\n",
    "label_encoders = {}\n",
    "for column in y.columns:\n",
    "    le = LabelEncoder()\n",
    "    y[column] = le.fit_transform(y[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "multi_output_model9 = MultiOutputClassifier(model)\n",
    "\n",
    "multi_output_model9.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predictions = multi_output_model9.predict([[12.05]])\n",
    "\n",
    "decoded_predictions = pd.DataFrame(columns=y.columns)\n",
    "for column in y.columns:\n",
    "    le = label_encoders[column]\n",
    "    decoded_predictions[column] = le.inverse_transform(predictions[:, list(y.columns).index(column)])\n",
    "\n",
    "print(decoded_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x.fractal_dim_se  x.fractal_dim_worst\n",
      "0          0.005667               0.1252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\3022969926.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\3022969926.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[column] = le.fit_transform(y[column])\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "X = data[['x.fractal_dim_mean']] \n",
    "y = data[['x.fractal_dim_se', 'x.fractal_dim_worst']] \n",
    "\n",
    "label_encoders = {}\n",
    "for column in y.columns:\n",
    "    le = LabelEncoder()\n",
    "    y[column] = le.fit_transform(y[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "multi_output_model10 = MultiOutputClassifier(model)\n",
    "\n",
    "multi_output_model10.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predictions = multi_output_model10.predict([[12.05]])\n",
    "\n",
    "decoded_predictions = pd.DataFrame(columns=y.columns)\n",
    "for column in y.columns:\n",
    "    le = label_encoders[column]\n",
    "    decoded_predictions[column] = le.inverse_transform(predictions[:, list(y.columns).index(column)])\n",
    "\n",
    "print(decoded_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelx10.joblib']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import load, dump\n",
    "dump(multi_output_model1, 'modelx1.joblib')\n",
    "dump(multi_output_model2, 'modelx2.joblib')\n",
    "dump(multi_output_model3, 'modelx3.joblib')\n",
    "dump(multi_output_model4, 'modelx4.joblib')\n",
    "dump(multi_output_model5, 'modelx5.joblib')\n",
    "dump(multi_output_model6, 'modelx6.joblib')\n",
    "dump(multi_output_model7, 'modelx7.joblib')\n",
    "dump(multi_output_model8, 'modelx8.joblib')\n",
    "dump(multi_output_model9, 'modelx9.joblib')\n",
    "dump(multi_output_model10, 'modelx10.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. MultiOutputRegressor expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[192], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m# Training the merged model\u001b[39;00m\n\u001b[0;32m     13\u001b[0m model_merged \u001b[39m=\u001b[39m MultiOutputRegressor(RandomForestRegressor())\n\u001b[1;32m---> 14\u001b[0m model_merged\u001b[39m.\u001b[39;49mfit(a, (b, c))\n\u001b[0;32m     16\u001b[0m \u001b[39m# Predicting with the merged model\u001b[39;00m\n\u001b[0;32m     17\u001b[0m predictions \u001b[39m=\u001b[39m model_merged\u001b[39m.\u001b[39mpredict(a)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\multioutput.py:198\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    196\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe base estimator should implement a fit method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 198\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mno_validation\u001b[39;49m\u001b[39m\"\u001b[39;49m, y\u001b[39m=\u001b[39;49my, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    200\u001b[0m \u001b[39mif\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    201\u001b[0m     check_classification_targets(y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:568\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[1;32m--> 568\u001b[0m     y \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    569\u001b[0m     out \u001b[39m=\u001b[39m y\n\u001b[0;32m    570\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1132\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[39mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1132\u001b[0m     y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1133\u001b[0m         y,\n\u001b[0;32m   1134\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1135\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1136\u001b[0m         ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1137\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1138\u001b[0m         input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1139\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1140\u001b[0m     )\n\u001b[0;32m   1141\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1142\u001b[0m     estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 915\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m     )\n\u001b[0;32m    920\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    921\u001b[0m     _assert_all_finite(\n\u001b[0;32m    922\u001b[0m         array,\n\u001b[0;32m    923\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. MultiOutputRegressor expected <= 2."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Assuming 'data' is a DataFrame containing the required columns\n",
    "\n",
    "# Extracting the features\n",
    "a = data['x.radius_mean'].values.reshape(-1, 1)\n",
    "b = data['x.radius_se'].values.reshape(-1, 1)\n",
    "c = data['x.radius_worst'].values.reshape(-1, 1)\n",
    "\n",
    "# Training the merged model\n",
    "model_merged = MultiOutputRegressor(RandomForestRegressor())\n",
    "model_merged.fit(a, (b, c))\n",
    "\n",
    "# Predicting with the merged model\n",
    "predictions = model_merged.predict(a)\n",
    "\n",
    "# Printing the predictions\n",
    "predictions_df = pd.DataFrame({'predictions_b': predictions[0], 'predictions_c': predictions[1]})\n",
    "print(predictions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\3341571010.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  modelA1.fit(a, b)\n",
      "C:\\Users\\Dhruv Kothari\\AppData\\Local\\Temp\\ipykernel_61864\\3341571010.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  modelB1.fit(a, c)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\";predictions_b, predictions_c = merged_model.predict(a)\\n\\n# Printing the predictions\\npredictions = pd.DataFrame({'predictions_b': predictions_b, 'predictions_c': predictions_c})\\nprint(predictions)\""
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the features\n",
    "a = data['x.radius_mean'].values.reshape(-1, 1)\n",
    "b = data['x.radius_se'].values.reshape(-1, 1)\n",
    "c = data['x.radius_worst'].values.reshape(-1, 1)\n",
    "\n",
    "# Training the individual models\n",
    "modelA1 = RandomForestRegressor()\n",
    "modelA1.fit(a, b)\n",
    "\n",
    "modelB1 = RandomForestRegressor()\n",
    "modelB1.fit(a, c)\n",
    "\n",
    "# Merging the models\n",
    "class MergedModel:\n",
    "    def __init__(self, modelA, modelB):\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions_b = self.modelA.predict(x)\n",
    "        predictions_c = self.modelB.predict(x)\n",
    "        return predictions_b, predictions_c\n",
    "\n",
    "merged_model = MergedModel(modelA1, modelB1)\n",
    "\n",
    "dump(multi_output_model1, 'model1.joblib')\n",
    "\n",
    "''';predictions_b, predictions_c = merged_model.predict(a)\n",
    "\n",
    "# Printing the predictions\n",
    "predictions = pd.DataFrame({'predictions_b': predictions_b, 'predictions_c': predictions_c})\n",
    "print(predictions)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features\n",
    "a = data['x.radius_mean'].values.reshape(-1, 1)\n",
    "b = data['x.radius_se'].values.reshape(-1, 1)\n",
    "c = data['x.radius_worst'].values.reshape(-1, 1)\n",
    "\n",
    "# Training the individual models\n",
    "modelA1 = RandomForestRegressor()\n",
    "modelA1.fit(a, b)\n",
    "\n",
    "modelB1 = RandomForestRegressor()\n",
    "modelB1.fit(a, c)\n",
    "\n",
    "# Merging the models\n",
    "class MergedModel:\n",
    "    def __init__(self, modelA, modelB):\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions_b = self.modelA.predict(x)\n",
    "        predictions_c = self.modelB.predict(x)\n",
    "        return predictions_b, predictions_c\n",
    "\n",
    "merged_model = MergedModel(modelA1, modelB1)\n",
    "\n",
    "dump(multi_output_model1, 'model1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features\n",
    "a = data['x.radius_mean'].values.reshape(-1, 1)\n",
    "b = data['x.radius_se'].values.reshape(-1, 1)\n",
    "c = data['x.radius_worst'].values.reshape(-1, 1)\n",
    "\n",
    "# Training the individual models\n",
    "modelA1 = RandomForestRegressor()\n",
    "modelA1.fit(a, b)\n",
    "\n",
    "modelB1 = RandomForestRegressor()\n",
    "modelB1.fit(a, c)\n",
    "\n",
    "# Merging the models\n",
    "class MergedModel:\n",
    "    def __init__(self, modelA, modelB):\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions_b = self.modelA.predict(x)\n",
    "        predictions_c = self.modelB.predict(x)\n",
    "        return [predictions_b, predictions_c]\n",
    "\n",
    "merged_model = MergedModel(modelA1, modelB1)\n",
    "\n",
    "dump(multi_output_model1, 'model1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features\n",
    "a = data['x.radius_mean'].values.reshape(-1, 1)\n",
    "b = data['x.radius_se'].values.reshape(-1, 1)\n",
    "c = data['x.radius_worst'].values.reshape(-1, 1)\n",
    "\n",
    "# Training the individual models\n",
    "modelA1 = RandomForestRegressor()\n",
    "modelA1.fit(a, b)\n",
    "\n",
    "modelB1 = RandomForestRegressor()\n",
    "modelB1.fit(a, c)\n",
    "\n",
    "# Merging the models\n",
    "class MergedModel:\n",
    "    def __init__(self, modelA, modelB):\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions_b = self.modelA.predict(x)\n",
    "        predictions_c = self.modelB.predict(x)\n",
    "        return predictions_b, predictions_c\n",
    "\n",
    "merged_model = MergedModel(modelA1, modelB1)\n",
    "\n",
    "dump(multi_output_model1, 'model1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features\n",
    "a = data['x.radius_mean'].values.reshape(-1, 1)\n",
    "b = data['x.radius_se'].values.reshape(-1, 1)\n",
    "c = data['x.radius_worst'].values.reshape(-1, 1)\n",
    "\n",
    "# Training the individual models\n",
    "modelA1 = RandomForestRegressor()\n",
    "modelA1.fit(a, b)\n",
    "\n",
    "modelB1 = RandomForestRegressor()\n",
    "modelB1.fit(a, c)\n",
    "\n",
    "# Merging the models\n",
    "class MergedModel:\n",
    "    def __init__(self, modelA, modelB):\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions_b = self.modelA.predict(x)\n",
    "        predictions_c = self.modelB.predict(x)\n",
    "        return predictions_b, predictions_c\n",
    "\n",
    "merged_model = MergedModel(modelA1, modelB1)\n",
    "\n",
    "dump(multi_output_model1, 'model1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features\n",
    "a = data['x.radius_mean'].values.reshape(-1, 1)\n",
    "b = data['x.radius_se'].values.reshape(-1, 1)\n",
    "c = data['x.radius_worst'].values.reshape(-1, 1)\n",
    "\n",
    "# Training the individual models\n",
    "modelA1 = RandomForestRegressor()\n",
    "modelA1.fit(a, b)\n",
    "\n",
    "modelB1 = RandomForestRegressor()\n",
    "modelB1.fit(a, c)\n",
    "\n",
    "# Merging the models\n",
    "class MergedModel:\n",
    "    def __init__(self, modelA, modelB):\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions_b = self.modelA.predict(x)\n",
    "        predictions_c = self.modelB.predict(x)\n",
    "        return predictions_b, predictions_c\n",
    "\n",
    "merged_model = MergedModel(modelA1, modelB1)\n",
    "\n",
    "dump(multi_output_model1, 'model1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features\n",
    "a = data['x.radius_mean'].values.reshape(-1, 1)\n",
    "b = data['x.radius_se'].values.reshape(-1, 1)\n",
    "c = data['x.radius_worst'].values.reshape(-1, 1)\n",
    "\n",
    "# Training the individual models\n",
    "modelA1 = RandomForestRegressor()\n",
    "modelA1.fit(a, b)\n",
    "\n",
    "modelB1 = RandomForestRegressor()\n",
    "modelB1.fit(a, c)\n",
    "\n",
    "# Merging the models\n",
    "class MergedModel:\n",
    "    def __init__(self, modelA, modelB):\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions_b = self.modelA.predict(x)\n",
    "        predictions_c = self.modelB.predict(x)\n",
    "        return predictions_b, predictions_c\n",
    "\n",
    "merged_model = MergedModel(modelA1, modelB1)\n",
    "\n",
    "dump(multi_output_model1, 'model1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features\n",
    "a = data['x.radius_mean'].values.reshape(-1, 1)\n",
    "b = data['x.radius_se'].values.reshape(-1, 1)\n",
    "c = data['x.radius_worst'].values.reshape(-1, 1)\n",
    "\n",
    "# Training the individual models\n",
    "modelA1 = RandomForestRegressor()\n",
    "modelA1.fit(a, b)\n",
    "\n",
    "modelB1 = RandomForestRegressor()\n",
    "modelB1.fit(a, c)\n",
    "\n",
    "# Merging the models\n",
    "class MergedModel:\n",
    "    def __init__(self, modelA, modelB):\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions_b = self.modelA.predict(x)\n",
    "        predictions_c = self.modelB.predict(x)\n",
    "        return predictions_b, predictions_c\n",
    "\n",
    "merged_model = MergedModel(modelA1, modelB1)\n",
    "\n",
    "dump(multi_output_model1, 'model1.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
